## Proyecto agroxAI

El proyecto tendrÃ¡ como finalidad la funciÃ³n de subir una imagen en la cual la IA entrenada con imagenes de plagas, arrojarÃ¡ resultado de que plaga puede ser, teniendo un nivel de confianza, mientras que hay un chat para poder responder preguntas de que tiene la planta o una parte de la fruta, como uvas, naranjas, mangos, etc.

## Objetivo General

Desarrollar una plataforma web que identifique plagas de interÃ©s econÃ³mico en cultivos de la regiÃ³n Ica mediante anÃ¡lisis de imÃ¡genes y asistencia conversacional, generando diagnÃ³sticos automÃ¡ticos y recomendaciones tÃ©cnicas.

## 1. Funciones clave

- Recibir una imagen
- Predecir la plaga
- Mostrar nivel confianza
- Evaluar severidad
- Generar una ficha tÃ©cnica
- Guardar el diagnÃ³stico
- Mantener un pequeÃ±o historial
- (Opcional) Permitir chat contextual por caso

## 2. Flujo de trabajo

1. Entrada: El usuario sube foto -> Se guarda en imagen.
2. Inferencia: El modelo analiza la foto -> Guarda resultados en diagnostico (con modelo_version).
3. Consumo:

- El usuario ve el resultado y la ficha_tecnica.
- El usuario chatea sobre el resultado (chat_sesion vinculado a diagnostico).

## 3. Contexto

- Base de datos en '/context/agroxBD'
- Reglas en 'AGENT.md'

## 4. Desarrollo

- Cada funciÃ³n que se cree deberÃ¡ ponerse en Snake_Case para poder identificar, antes de cada funciÃ³n tienes que mostrar comentarios de que es lo que hace, con que se conecta especificamente
- Las variables tendrÃ¡n formato camelCase
- Despues de cada artificio tambiÃ©n colocar comentarios
- Aplica la metodologÃ­a TDD
- La parte del cliente serÃ¡ creada con React
- La parte del backend se gestionarÃ¡ con NextJS para poder analizar con IA
- Si no hay contexto de un directorio a donde se guardarÃ¡n las imagenes, usa urls de ejemplo para despuÃ©s poder reemplazarlos

## 5. DiseÃ±o

- Se utilizarÃ¡ MUI: Material UI, libreria de React para los estilos
- Si hay una idea que tengo para poner animaciones usa Framer Notion
- Si se requiere crear propios estilos se harÃ¡ con CSS puro.
- El modelo de las pÃ¡ginas estÃ¡n en '/model/Page.docx'

## 6. Estructura de carpetas

/src
â”œâ”€â”€ /app # Rutas de la aplicaciÃ³n (App Router)
â”‚ â”œâ”€â”€ /api # Endpoints API (si no usas Server Actions)
â”‚ â”‚ â”œâ”€â”€ /chat # Endpoint para el chat
â”‚ â”‚ â””â”€â”€ /diagnose # Endpoint para procesar imagen
â”‚ â”œâ”€â”€ /dashboard # Panel principal (historial)
â”‚ â”œâ”€â”€ /diagnostico # Vista de resultados
â”‚ â”‚ â””â”€â”€ [id] # page.tsx (Detalle del diagnÃ³stico)
â”‚ â”œâ”€â”€ /ficha # Fichas tÃ©cnicas
â”‚ â”‚ â””â”€â”€ [plagaId] # page.tsx
â”‚ â”œâ”€â”€ /admin # Panel de administraciÃ³n (protegido)
â”‚ â”œâ”€â”€ layout.tsx # Layout principal (Navbar, ThemeRegistry)
â”‚ â””â”€â”€ page.tsx # Landing / Upload inicial
â”œâ”€â”€ /components # Componentes React
â”‚ â”œâ”€â”€ /ui # Ãtomos (Botones, Inputs, Cards de MUI)
â”‚ â”œâ”€â”€ /upload # Dropzone, Preview
â”‚ â”œâ”€â”€ /chat # ChatBubble, ChatInput
â”‚ â””â”€â”€ /layout # Navbar, Sidebar, Footer
â”œâ”€â”€ /lib # Configuraciones y utilidades
â”‚ â”œâ”€â”€ supabase.ts # Cliente de Supabase (Singleton)
â”‚ â”œâ”€â”€ openai.ts # ConfiguraciÃ³n cliente IA (si usas OpenAI)
â”‚ â””â”€â”€ utils.ts # Helpers (formateo de fechas, etc.)
â”œâ”€â”€ /services # LÃ³gica de negocio (Backend logic)
â”‚ â”œâ”€â”€ aiService.ts # FunciÃ³n que habla con la IA
â”‚ â”œâ”€â”€ dbService.ts # Funciones para guardar/leer de Supabase
â”‚ â””â”€â”€ storageService.ts # Funciones para subir archivos
â”œâ”€â”€ /types # Definiciones TypeScript (DB, Props)
â””â”€â”€ /theme # ConfiguraciÃ³n de Material UI

## 7. DetecciÃ³n de imagenes/plagas

ğŸ›  Funciones de cada Componente

1. GestiÃ³n de ImÃ¡genes
   public/img/ (Referencia):

    FunciÃ³n: Contiene las imÃ¡genes "bonitas" y explicativas que se muestran en las fichas tÃ©cnicas de la plaga o cultivo.
        public/logo/ 
        'logoGrande' para la presentaciÃ³n de la pÃ¡gina
        'logo' para el navbar
    public/uploads/ (DiagnÃ³stico):

    FunciÃ³n: AlmacÃ©n temporal de las fotos que toman los agricultores.

    Flujo: Cuando el usuario hace el POST, tu route.ts guarda el archivo aquÃ­ para que React pueda mostrarla en pantalla (<img src="/uploads/foto_usuario.jpg" />).

    training_dataset/ (Entrenamiento):
        FunciÃ³n: Materia prima exclusiva para Google Teachable Machine.
        Nota: Esta carpeta NO es leÃ­da por tu aplicaciÃ³n web. Solo la usas tÃº manualmente para generar el modelo.

2. El Motor de Inteligencia Artificial (models/)
    - model.json: Define la estructura de la red neuronal. Le dice a Next.js quÃ© tamaÃ±o de imagen esperar (224x224) y cuÃ¡ntas salidas hay (Sana, Oidium).
    - weights.bin: Contiene lo que la IA "aprendiÃ³" mirando tu carpeta training_dataset. Sin este archivo, la IA no sabe distinguir nada.

3. El Backend LÃ³gico (app/api/diagnosticar/route.ts)
   Es el director de orquesta. Realiza los siguientes pasos en milisegundos:

- Recibe la imagen del Frontend.

- Guarda la imagen fÃ­sica en public/uploads.

- Carga el cerebro (model.json + weights.bin) usando @tensorflow/tfjs-node.

- Predice la enfermedad (ej. "Oidium").

- Calcula la Severidad (LÃ³gica MVP):

- Si Confianza IA > 90% â†’ Severidad Alta/CrÃ­tica.

- Si Confianza IA < 90% â†’ Severidad Media/Preventiva.

- Responde al Frontend con el JSON final.

- ğŸ”„ Flujo de Datos (Resumen)
        Usuario: Sube foto ğŸ“¸.

        Next.js: Guarda foto en disco ğŸ’¾ (public/uploads).

        Next.js: Consulta al modelo ğŸ§  (models/).

        Modelo: Dice "Es Oidium" ğŸ¦ .

        Next.js: Aplica regla de negocio "Es Severo porque estoy 99% seguro" âš ï¸.

        Frontend: Muestra alerta roja y ficha tÃ©cnica ğŸš¨.
